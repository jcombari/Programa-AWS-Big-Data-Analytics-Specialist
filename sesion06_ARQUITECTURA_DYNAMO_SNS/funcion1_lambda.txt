import boto3
import json

import json, urllib, boto3, csv

s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb')

def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']
    s3_file_name = event['Records'][0]['s3']['object']['key']

    resp = s3_client.get_object(Bucket = bucket, Key = s3_file_name)
    data = resp['Body'].read()
    print(data)



****************************************
import json, urllib, boto3, csv

s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb')

def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']
    s3_file_name = event['Records'][0]['s3']['object']['key']
    resp = s3_client.get_object(Bucket = bucket, Key = s3_file_name)
    data = resp['Body'].read().decode("UTF-8")
    print(data)


***************************************

import json, urllib, boto3, csv

s3_client = boto3.client('s3')
s3 = boto3.resource('s3')


dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('Inventory');


def lambda_handler(event, context):
    bucket = event['Records'][0]['s3']['bucket']['name']

    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])
    localFilename = '/tmp/inventory.txt'
    s3.meta.client.download_file(bucket, key, localFilename)
    
    
    with open(localFilename) as csvfile:
        reader = csv.DictReader(csvfile, delimiter=',')
        rowCount = 0
        
        for row in reader:
            rowCount += 1
            
            print(row['store'], row['item'], row['count'])
            
            table.put_item(
                  Item={
                    'store':  row['store'],
                    'item':   row['item'],
                    'count':  int(row['count'])})
        return "%d counts inserted" % rowCount

***************************************




******************************


